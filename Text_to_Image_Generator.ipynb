{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hN6i4v1_QTp",
        "outputId": "dddd7e2b-a88f-4a58-c9c1-4e60eb439b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install diffusers transformers accelerate pillow torch torchvision torchaudio gradio -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import diffusers\n",
        "print(\"‚úÖ Diffusers installed successfully! Version:\", diffusers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE3EZT2s_VF2",
        "outputId": "70f906bd-a79a-4445-baac-c6d3a4eca1e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Diffusers installed successfully! Version: 0.35.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # True = GPU, False = CPU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5Lctv9iGaQt",
        "outputId": "bea646d1-af08-4b4c-c1df-ed62a2c9abce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS = {\n",
        "    \"Realistic\": \"runwayml/stable-diffusion-v1-5\",\n",
        "    \"Cartoon\": \"prompthero/openjourney\",\n",
        "    \"Oil Painting\": \"nitrosocke/mo-di-diffusion\"\n",
        "}\n",
        "\n",
        "def load_model(style):\n",
        "    model_id = MODELS[style]\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)\n",
        "    if torch.cuda.is_available():\n",
        "        pipe = pipe.to(\"cuda\")\n",
        "    return pipe\n",
        "\n",
        "pipe_cache = {}\n",
        "def get_pipe(style):\n",
        "    if style not in pipe_cache:\n",
        "        pipe_cache[style] = load_model(style)\n",
        "    return pipe_cache[style]\n"
      ],
      "metadata": {
        "id": "T_WsqJV7_30T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, style, num_images):\n",
        "    pipe = get_pipe(style)\n",
        "    images = pipe([prompt] * num_images).images\n",
        "    output_paths = []\n",
        "\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "    for i, img in enumerate(images):\n",
        "        path = f\"outputs/{style}_{i}.png\"\n",
        "        img.save(path)\n",
        "        output_paths.append(path)\n",
        "    return output_paths\n"
      ],
      "metadata": {
        "id": "RxUwoJojDcsx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align:center;'>üé® Text-to-Image Generator using Stable Diffusion</h1>\")\n",
        "    gr.Markdown(\"Turn any text prompt into an image in seconds! Choose a **style**, enter your idea, and click **Generate**.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(label=\"Enter your prompt\", placeholder=\"e.g. a futuristic city at sunset\")\n",
        "        style = gr.Dropdown(choices=list(MODELS.keys()), value=\"Realistic\", label=\"Select style\")\n",
        "        num_images = gr.Slider(1, 3, value=1, step=1, label=\"Number of images\")\n",
        "\n",
        "    generate_btn = gr.Button(\"üöÄ Generate Images\")\n",
        "    gallery = gr.Gallery(label=\"Generated Images\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"A cat wearing sunglasses on the beach\", \"Cartoon\", 1],\n",
        "            [\"A portrait of an astronaut painted in oil\", \"Oil Painting\", 1],\n",
        "            [\"A futuristic car racing through neon city\", \"Realistic\", 1],\n",
        "        ],\n",
        "        inputs=[prompt, style, num_images]\n",
        "    )\n",
        "\n",
        "    generate_btn.click(generate, [prompt, style, num_images], gallery)\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "LgiALiy4Dk9U",
        "outputId": "fce021e0-057d-4a79-ff88-67513faf6c6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3e5e09bee010166c3a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3e5e09bee010166c3a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTFc1IwBDoco"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}